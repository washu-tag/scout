- name: Create namespace
  kubernetes.core.k8s:
    name: '{{ spark_defaults_configmap_namespace }}'
    api_version: v1
    kind: Namespace
    state: present

- name: Create Spark ConfigMap
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: '{{ spark_defaults_configmap_name }}'
        namespace: '{{ spark_defaults_configmap_namespace }}'
      data:
        spark-defaults.conf: |
          spark.hadoop.fs.s3a.access.key {{ s3_username }}
          spark.hadoop.fs.s3a.secret.key {{ s3_password }}
          spark.hadoop.fs.s3a.endpoint {{ s3_endpoint }}
          spark.hadoop.fs.s3a.endpoint.region {{ s3_region | default("us-east-1") }}
          spark.databricks.delta.schema.autoMerge.enabled true
          spark.databricks.delta.merge.repartitionBeforeWrite.enabled true
          spark.sql.extensions io.delta.sql.DeltaSparkSessionExtension
          spark.sql.catalog.spark_catalog org.apache.spark.sql.delta.catalog.DeltaCatalog
          spark.hadoop.fs.s3a.path.style.access true
          spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
          spark.hadoop.hive.metastore.uris {{ hive_metastore_endpoint }}
          spark.sql.warehouse.dir {{ hive_warehouse | replace('s3:', 's3a:') }}
          spark.driver.extraJavaOptions -Divy.cache.dir=/tmp -Divy.home=/tmp
          spark.executor.memory {{ spark_memory | default("1g") }}
          spark.driver.memory {{ spark_memory | default("1g") }}
