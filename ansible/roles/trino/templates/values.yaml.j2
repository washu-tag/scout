# Server configuration (cluster-wide settings)
server:
  workers: {{ trino_worker_count }}
  config:
    query:
      # Cluster-wide max memory = workers × worker_heap × per_node_fraction
      maxMemory: "{{ trino_worker_max_heap | multiply_memory(trino_worker_count * trino_per_node_query_memory_fraction) }}B"
    authenticationType: PASSWORD

# Access control configuration using Helm chart's built-in support
accessControl:
  type: configmap
  refreshPeriod: 60s
  configFile: "rules.json"
  rules:
    rules.json: |-
      {
        "catalogs": [
          {
            "user": "{{ trino_readonly_user }}",
            "catalog": "delta",
            "allow": "read-only"
          },
          {
            "user": "{{ trino_admin_user }}",
            "catalog": "delta",
            "allow": "all"
          },
          {
            "group": ".*",
            "catalog": "system",
            "allow": "read-only"
          },
          {
            "user": ".*",
            "catalog": "delta",
            "allow": "none"
          }
        ]
      }

# Authentication configuration - password-based to prevent user impersonation
auth:
  passwordAuth: |-
    # Format: username:bcrypt_hash
    # Passwords are hashed with bcrypt (cost 8) for performance
    {{ trino_admin_user }}:{{ trino_admin_password | password_hash('bcrypt', rounds=8) }}
    {{ trino_readonly_user }}:{{ trino_readonly_password | password_hash('bcrypt', rounds=8) }}

additionalConfigProperties:
  - http-server.authentication.allow-insecure-over-http=true
  - internal-communication.shared-secret={{ trino_internal_shared_secret }}

# Coordinator configuration
# JVM heap = trino_coordinator_max_heap, pod memory limit = 2x heap for off-heap overhead
coordinator:
  jvm:
    maxHeapSize: {{ trino_coordinator_max_heap }}
  config:
    memory:
      heapHeadroomPerNode: "" # Per https://trino.io/docs/current/admin/properties-resource-management.html#memory-heap-headroom-per-node defaults to 30% of maxHeapSize
    query:
      maxMemoryPerNode: "{{ trino_coordinator_max_heap | multiply_memory(trino_per_node_query_memory_fraction) }}B"
  resources: {{ trino_coordinator_resources | to_json }}
  annotations:
    prometheus.io/trino_scrape: 'true'

# Worker configuration
# JVM heap = trino_worker_max_heap, pod memory limit = 2x heap for off-heap overhead
worker:
  jvm:
    maxHeapSize: {{ trino_worker_max_heap }}
  config:
    memory:
      heapHeadroomPerNode: ""
    query:
      maxMemoryPerNode: "{{ trino_worker_max_heap | multiply_memory(trino_per_node_query_memory_fraction) }}B"
  resources: {{ trino_worker_resources | to_json }}
  annotations:
    prometheus.io/trino_scrape: 'true'

# Catalogs
catalogs:
  delta: |
    connector.name=delta_lake
    hive.metastore.uri={{ hive_metastore_endpoint }}
    delta.security=ALLOW_ALL
    delta.enable-non-concurrent-writes=true
    fs.native-s3.enabled=true
    s3.aws-access-key={{ s3_lake_writer }}
    s3.aws-secret-key={{ s3_lake_writer_secret }}
    s3.region={{ s3_region }}
    s3.endpoint={{ s3_endpoint }}
    s3.path-style-access=true