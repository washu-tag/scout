# Server configuration (cluster-wide settings)
server:
  workers: {{ trino_worker_count }}
  config:
    query:
      # Cluster-wide max memory = workers × worker_heap × per_node_fraction
      maxMemory: "{{ trino_worker_max_heap | multiply_memory(trino_worker_count * trino_per_node_query_memory_fraction) }}B"

{% if aws_deployment %}
serviceAccount:
  create: false
  name: '{{ lake_reader_service_account }}'
{% endif %}

# Coordinator configuration
# JVM heap = trino_coordinator_max_heap, pod memory limit = 2x heap for off-heap overhead
coordinator:
  jvm:
    maxHeapSize: {{ trino_coordinator_max_heap }}
  config:
    memory:
      heapHeadroomPerNode: "" # Per https://trino.io/docs/current/admin/properties-resource-management.html#memory-heap-headroom-per-node defaults to 30% of maxHeapSize
    query:
      maxMemoryPerNode: "{{ trino_coordinator_max_heap | multiply_memory(trino_per_node_query_memory_fraction) }}B"
  resources: {{ trino_coordinator_resources | to_json }}
  annotations:
    prometheus.io/trino_scrape: 'true'

# Worker configuration
# JVM heap = trino_worker_max_heap, pod memory limit = 2x heap for off-heap overhead
worker:
  jvm:
    maxHeapSize: {{ trino_worker_max_heap }}
  config:
    memory:
      heapHeadroomPerNode: ""
    query:
      maxMemoryPerNode: "{{ trino_worker_max_heap | multiply_memory(trino_per_node_query_memory_fraction) }}B"
  resources: {{ trino_worker_resources | to_json }}
  annotations:
    prometheus.io/trino_scrape: 'true'

# Catalogs
catalogs:
  delta: |
    connector.name=delta_lake
    hive.metastore.uri={{ hive_metastore_endpoint_readonly }}
    delta.security=READ_ONLY
    fs.native-s3.enabled=true
    s3.region={{ s3_region }}
{% if not aws_deployment %}
    s3.aws-access-key={{ s3_lake_reader }}
    s3.aws-secret-key={{ s3_lake_reader_secret }}
    s3.endpoint={{ s3_endpoint }}
    s3.path-style-access=true
{% else %}
    s3.path-style-access=false
{% endif %}
