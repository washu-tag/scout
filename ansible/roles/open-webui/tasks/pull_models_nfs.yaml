---
# Pull Ollama models to shared NFS from staging cluster (air-gapped mode)
# Models are pulled to NFS on staging; production Ollama mounts NFS read-only
# See ADR 0008 for architecture details

- name: Create model download Job on staging
  kubernetes.core.k8s:
    kubeconfig: '{{ staging_kubeconfig }}'
    state: present
    definition:
      apiVersion: batch/v1
      kind: Job
      metadata:
        generateName: 'ollama-download-models-'
        namespace: '{{ staging_ollama_namespace | default("ollama-staging") }}'
        labels:
          app: ollama-download-models
      spec:
        ttlSecondsAfterFinished: 3600 # Clean up 1 hour after completion
        backoffLimit: 2
        template:
          metadata:
            labels:
              app: ollama-download-models
          spec:
            restartPolicy: OnFailure
            containers:
              - name: ollama
                image: 'ollama/ollama:{{ ollama_version | default("latest") }}'
                env:
                  - name: OLLAMA_MODELS
                    value: /nfs/ollama/models
                command:
                  - /bin/sh
                  - -c
                  - |
                    set -e
                    echo "Starting Ollama server..."
                    ollama serve &
                    sleep 5

                    echo "Pulling models to NFS..."
                    {% for model in ollama_models %}
                    echo "Pulling model: {{ model }}"
                    ollama pull {{ model }}
                    {% endfor %}

                    echo "All models pulled successfully to NFS"
                volumeMounts:
                  - name: nfs-models
                    mountPath: /nfs/ollama
            volumes:
              - name: nfs-models
                hostPath:
                  path: '{{ ollama_nfs_path }}'
                  type: DirectoryOrCreate
  register: staging_job

- name: Wait for staging model download Job to complete
  kubernetes.core.k8s_info:
    kubeconfig: '{{ staging_kubeconfig }}'
    api_version: batch/v1
    kind: Job
    namespace: '{{ staging_ollama_namespace | default("ollama-staging") }}'
    label_selectors:
      - app=ollama-download-models
  register: job_status
  until: >-
    job_status.resources | length > 0 and
    (job_status.resources[0].status.succeeded | default(0) > 0 or
     job_status.resources[0].status.failed | default(0) > 0)
  retries: 120 # 2 hours max (large models take time)
  delay: 60

- name: Check if staging Job succeeded
  ansible.builtin.fail:
    msg: "Staging model download Job failed. Check logs with: kubectl --kubeconfig={{ staging_kubeconfig }} logs -n {{ staging_ollama_namespace | default('ollama-staging') }} -l app=ollama-download-models"
  when: job_status.resources[0].status.failed | default(0) > 0

- name: Models available on NFS
  ansible.builtin.debug:
    msg: "Models successfully pulled to NFS at {{ ollama_nfs_path }}. Production Ollama will mount this path read-only."
