---
# Pull Ollama models to shared NFS from staging cluster (air-gapped mode)
# Models are pulled to NFS on staging; cluster Ollama mounts NFS read-only
# Job runs in background - does not block cluster installation
# See ADR 0008 for architecture details

- name: Create model download Job on staging
  kubernetes.core.k8s:
    kubeconfig: '{{ kubeconfig_yaml }}'
    state: present
    definition:
      apiVersion: batch/v1
      kind: Job
      metadata:
        generateName: 'ollama-download-models-'
        namespace: '{{ staging_ollama_namespace }}'
        labels:
          app: ollama-download-models
      spec:
        ttlSecondsAfterFinished: 3600 # Clean up 1 hour after completion
        backoffLimit: 2
        template:
          metadata:
            labels:
              app: ollama-download-models
          spec:
            restartPolicy: OnFailure
            containers:
              - name: ollama
                image: 'ollama/ollama:{{ ollama_version | default("latest") }}'
                env:
                  - name: OLLAMA_MODELS
                    value: /nfs/ollama/models
                command:
                  - /bin/sh
                  - -c
                  - |
                    set -e
                    echo "Starting Ollama server..."
                    ollama serve &
                    sleep 5

                    echo "Pulling models to NFS..."
                    {% for model in ollama_models %}
                    echo "Pulling model: {{ model }}"
                    ollama pull {{ model }}
                    {% endfor %}

                    echo "All models pulled successfully to NFS"
                volumeMounts:
                  - name: nfs-models
                    mountPath: /nfs/ollama
            volumes:
              - name: nfs-models
                hostPath:
                  path: '{{ ollama_nfs_path }}'
                  type: DirectoryOrCreate
  delegate_to: "{{ groups['staging'][0] }}"

- name: Model download Job started on staging
  ansible.builtin.debug:
    msg: >-
      Model download Job created on staging cluster in {{ staging_ollama_namespace }} namespace.
      Models will download to NFS in the background. Check status on staging with:
      kubectl get jobs -n {{ staging_ollama_namespace }} -l app=ollama-download-models
