---
k3s_cluster:
  children:
    server:
      hosts:
        FQDN-leader.edu:
          ansible_connection: local
          ansible_python_interpreter: /usr/bin/python3
          k3s_control_node: true
          external_url: alt.fqdn.edu # omit to use FQDN-leader.edu
    agents:
      hosts:
        FQDN-worker-1.edu:
          ansible_connection: local
          ansible_python_interpreter: /usr/bin/python3
  vars:
    s3_username: 'minio'
    s3_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    s3_region: 'us-east-1'
    k3s_token: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    slack_token: $(echo $SLACK_TOKEN | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    slack_channel_id: $(echo $SLACK_CHANNEL | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    kubeconfig_group: '<name of the linux group that should be able to run kubectl>'
    jupyter_auth_class: dummy # dummy or github
    github_client_id: $(echo $CLIENT_ID | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    github_client_secret: $(echo $CLIENT_SECRET | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    github_organization: 'org'
    jupyter_dummy_password: $(echo $JH_DUMMY_PASSWORD | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    jupyter_allowed_users: [] # empty list means all users can log in
    jupyter_metrics_api_token: $(openssl rand -hex 32  | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    postgres_user: 'scout'
    postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    postgres_superuser_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    superset_secret: $(openssl rand -base64 42 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)

    # Namespaces that can be changed
    hive_namespace: hive
    postgres_cluster_namespace: cloudnative-pg
    prometheus_namespace: prometheus

    # Local paths
    base_dir: /var/lib/rancher/k3s/storage # Path to directory for container images and sandbox data
    scout_repo_dir: /scout/data/scout
    minio_dir: /scout/data/minio
    temporal_cassandra_dir: /scout/persistence/cassandra
    temporal_elasticsearch_dir: /scout/persistence/elasticsearch
    postgres_dir: /scout/persistence/postgres
    prometheus_dir: /scout/monitoring/prometheus
    loki_dir: /scout/monitoring/loki
    grafana_dir: /scout/monitoring/grafana
    jaeger_dir: /scout/monitoring/jaeger
    jupyter_dir: /scout/data/jupyter
    orchestration_data_dir: /scout/data/orchestration

    # Resources
    hl7_transformer_spark_memory: 8g
    jupyter_spark_memory: 8g
    temporal_cassandra_init_heap: 2G
    temporal_cassandra_max_heap: 8G

    # You probably don't want to change these unless you know these items will be
    # stored in different locations on your system
    helm_plugins_dir: '/root/.local/share/helm/plugins'
    kubeconfig_yaml: '/etc/rancher/k3s/k3s.yaml'

    # Do not change the values below, they are hard-coded various places
    extractor_namespace: extractor
    minio_tenant_namespace: minio-scout
    grafana_namespace: grafana
    loki_namespace: loki
    temporal_namespace: temporal

    # computed values, used across playbooks
    s3_endpoint: 'http://minio.{{ minio_tenant_namespace }}'
    hive_warehouse: 's3a://lake/hive' # Hadoop requires the s3a prefix, it is used just like s3://
    hive_metastore_endpoint: 'thrift://hive-metastore.{{ hive_namespace }}:9083'
    server_hostname: '{{ hostvars[groups["server"][0]].external_url | default(groups["server"][0]) }}'
    # End do not change
