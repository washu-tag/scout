---
server:
  hosts:
    FQDN-leader.edu:
      ansible_connection: local
      ansible_python_interpreter: /usr/bin/python3
      k3s_control_node: true
      external_url: alt.fqdn.edu # omit to use FQDN-leader.edu
workers:
  hosts:
    FQDN-worker-1.edu:
      ansible_connection: local
      ansible_python_interpreter: /usr/bin/python3
gpu_workers:
  hosts:
    FQDN-gpu-1.edu:
      ansible_connection: local
      ansible_python_interpreter: /usr/bin/python3
agents:
  children:
    workers:
    gpu_workers:
k3s_cluster:
  children:
    server:
    agents:
  vars:
    # K3s config
    k3s_version: v1.32.3+k3s1 # Leave blank for latest stable
    k3s_token: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    kubeconfig_group: '<name of the linux group that should be able to run kubectl>'

    # Minio config, ensure passwords meet complexity requirements (must be >=8 characters)
    minio_storage_size: 750Gi
    s3_username: minio
    s3_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    s3_region: us-east-1
    s3_lake_reader: lake-reader
    s3_lake_reader_secret: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    s3_lake_writer: lake-writer
    s3_lake_writer_secret: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    s3_loki_writer: loki-writer
    s3_loki_writer_secret: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)

    # Monitor config
    prometheus_storage_size: 100Gi
    loki_storage_size: 100Gi
    grafana_storage_size: 50Gi
    grafana_alert_contact_point: slack # email or slack
    grafana_smtp_host: '' # Include the port in the value
    grafana_smtp_user: $(echo $SMTP_USER | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    grafana_smtp_password: $(echo $SMTP_PASSWORD | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    grafana_smtp_from_address: ''
    grafana_smtp_from_name: 'Scout'
    grafana_smtp_skip_verify: false
    grafana_email_recipients: [''] # Grafana validation requires an address if using email
    slack_token: $(echo $SLACK_TOKEN | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    slack_channel_id: $(echo $SLACK_CHANNEL | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)

    # Jupyter config
    jupyter_auth_class: dummy # dummy or github
    github_client_id: $(echo $CLIENT_ID | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    github_client_secret: $(echo $CLIENT_SECRET | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    github_organization: org
    jupyter_dummy_password: $(echo $JH_DUMMY_PASSWORD | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    jupyter_allowed_users: [] # empty list means all users can log in
    jupyter_metrics_api_token: $(openssl rand -hex 32  | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    jupyter_prepuller_continuous: false
    jupyter_hub_storage_size: 15Gi
    jupyter_singleuser_storage_size: 250Gi

    # Postgres config
    postgres_user: scout
    postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    hive_postgres_user: hive
    hive_postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    superset_postgres_user: superset
    superset_postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    postgres_superuser_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    postgres_resources:
      requests:
        cpu: 4
        memory: 64Gi
      limits:
        cpu: 6
        memory: 96Gi
    postgres_storage_size: 100Gi
    postgres_parameters: # Strings only, no numbers allowed.
      max_connections: '100'
      shared_buffers: '16GB'
      effective_cache_size: '48GB'
      maintenance_work_mem: '2GB'
      checkpoint_completion_target: '0.9'
      wal_buffers: '16MB'
      default_statistics_target: '500'
      random_page_cost: '4'
      effective_io_concurrency: '1'
      work_mem: '2GB'
      huge_pages: 'try'
      min_wal_size: '4GB'
      max_wal_size: '16GB'
      max_worker_processes: '4'
      max_parallel_workers_per_gather: '2'
      max_parallel_workers: '4'
      max_parallel_maintenance_workers: '2'

    # Superset config
    superset_secret: $(openssl rand -base64 42 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)

    # Orchestrator config
    cassandra_storage_size: 300Gi
    elasticsearch_storage_size: 100Gi

    # Namespaces that can be changed
    hive_namespace: hive
    postgres_cluster_namespace: cloudnative-pg
    prometheus_namespace: prometheus
    grafana_namespace: grafana
    loki_namespace: loki
    ollama_namespace: ollama
    gpu_operator_namespace: gpu-operator

    # Local paths
    base_dir: /var/lib/rancher/k3s/storage # Path to directory for container images and sandbox data
    scout_repo_dir: /scout/data/scout
    minio_dir: /scout/data/minio
    temporal_cassandra_dir: /scout/persistence/cassandra
    temporal_elasticsearch_dir: /scout/persistence/elasticsearch
    postgres_dir: /scout/persistence/postgres
    prometheus_dir: /scout/monitoring/prometheus
    loki_dir: /scout/monitoring/loki
    grafana_dir: /scout/monitoring/grafana
    jupyter_dir: /scout/data/jupyter
    extractor_data_dir: /ceph/input/data

    # Parameters for optional PACS instances, only intended for use in development
    orthanc_namespace: orthanc
    dcm4chee_namespace: dcm4chee
    orthanc_dicom_port: 4242
    orthanc_dir: /scout/data/orthanc
    dcm4chee_dir: /scout/data/dcm4chee

    # Within the container mounted paths
    hl7logs_root_dir: /data
    modality_map_path: /data/modality_mapping_codes.csv

    # Object storage paths
    lake_bucket: lake
    scratch_bucket: scratch
    hl7_path: 's3://{{ lake_bucket }}/hl7'
    scratch_path: 's3://{{ scratch_bucket }}'
    delta_lake_path: 's3a://{{ lake_bucket }}/delta' # Hadoop requires the s3a prefix, it is used just like s3://

    # Database table names
    report_delta_table_name: reports
    ingest_postgres_table_name: ingest

    # Extractor performance tuning
    hl7log_extractor_timeout: 480
    hl7log_extractor_heartbeat_timeout: 30
    hl7log_extractor_concurrency: 150
    hl7_transformer_timeout: 60

    # Resources
    hl7_transformer_spark_memory: 8g
    jupyter_spark_memory: 8g
    temporal_cassandra_init_heap: 2G
    temporal_cassandra_max_heap: 8G

    # BEGIN - DO NOT CHANGE
    # You probably don't want to change these unless you know these items will be
    # stored in different locations on your system
    helm_plugins_dir: /root/.local/share/helm/plugins
    kubeconfig_yaml: /etc/rancher/k3s/k3s.yaml

    # Do not change the values below, they are hard-coded various places
    extractor_namespace: extractor
    minio_tenant_namespace: minio-scout
    temporal_namespace: temporal

    # computed values, used across playbooks
    s3_endpoint: 'http://minio.{{ minio_tenant_namespace }}'
    hive_metastore_endpoint: 'thrift://hive-metastore.{{ hive_namespace }}:9083'
    server_hostname: '{{ hostvars[groups["server"][0]].external_url | default(groups["server"][0]) }}'
    # END - DO NOT CHANGE
