spring:
  application:
    name: log-extractor
  temporal:
    connection:
      target: 'temporal-frontend.temporal:7233'
    namespace: default
    start-workers: true
    workers-auto-discovery:
      packages:
        - edu.washu.tag.extractor.hl7log.activity
        - edu.washu.tag.extractor.hl7log.workflow
  flyway:
    enabled: true
    baseline-on-migrate: true
    locations: classpath:db/migration
  # Write an external config that fills these in with your database connection details
  datasource:
    #    url: jdbc:postgresql://postgres.postgres:5432/scout
    #    username: postgres
    #    password: postgres
    driver-class-name: org.postgresql.Driver
s3:
  endpoint: 'http://minio.minio:9000'
  region: us-east-1
  max-connections: 50
scout:
  # Placeholders for default workflow arguments that can be configured from outside and overridden in the workflow
  workflowArgDefaults:
    ingestHl7Log:
      logsRootPath: ''
      scratchSpaceRootPath: ''
      hl7OutputPath: ''
      # Timeout (in minutes) for log split and upload activity
      splitAndUploadTimeout: 180
      # This is to limit I/O contention during the split and upload operation (java worker) and to try to hit a sweet spot of efficiency
      # during the delta lake insert (python worker). It's been tested on 1.3-1.4MB log files, as well as 15-45MB log files.
      splitAndUploadConcurrency: 150
    ingestHl7ToDeltaLake:
      # Timeout (in minutes) for transform and upload to delta lake activity
      deltaIngestTimeout: 60
      modalityMapPath: ''
      reportTableName: ''
